<html lang="en-US">
<!-- InstanceBegin template="/Templates/CanvasPage.dwt" codeOutsideHTMLIsLocked="false" -->
<head>
<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1">
<!-- InstanceBeginEditable name="doctitle" -->
<title>Canvas Template</title>
<!-- InstanceEndEditable -->
<!--
<link rel="stylesheet" media="all" href="https://du11hjcvx0uqb.cloudfront.net/br/dist/brandable_css/69d640e59b804992771ec1fed57a5039/variables-8391c84da435c9cfceea2b2b3317ff66.css">
<link rel="stylesheet" media="all" href="https://du11hjcvx0uqb.cloudfront.net/br/dist/brandable_css/responsive_layout_normal_contrast/bundles/common-c626ffd3ae.css">
<link rel="stylesheet" media="all" href="https://du11hjcvx0uqb.cloudfront.net/br/dist/brandable_css/no_variables/bundles/wiki_page-46e7e026f6.css">
<link rel="stylesheet" media="all" href="https://instructure-uploads.s3.us-east-1.amazonaws.com/account_74070000000000001/attachments/1525105/canvas.css">
-->
<!-- InstanceBeginEditable name="head" -->
<!-- InstanceEndEditable -->
</head>
<body style="margin-bottom: 5em;margin-top: 3em;margin-left: 20em;margin-right: 20em">
<div class="show-content user_content clearfix enhanced">
  <h1 class="page-title">Canvas Page</h1>
  <!-- Start Custom HTML for Canvas Page --> 
  <!-- InstanceBeginEditable name="content" -->
  <h2 class="section-header" style="">Announcements</h2>
  <div class="section-body" style="padding: 0 10px 10px 10px;border: solid #ccc 1px;overflow: hidden">
    <p>No Class on Wednesday - MBA Trips scheduled</p>
    <p>Homework Assignment is not ready yet since proposals are due today. I'll release the assignment today or tomorrow once I can select the proposals</p>
    <p>Major change to the schedule.  Because we spent extra time on the Python section of the course I decided to drop Unit 3 - Regression Analysis.  
      It is not that it isn't important, but we don't have time to cover it well and it still cover surveys completely.  Rather than cover each topic only half way
      I decided to cut the last unit.</p>
  </div>
  <h2 class="section-header" style="">Homework Assignment</h2>
  <div class="section-body" style="padding: 0 10px 10px 10px;border: solid #ccc 1px;overflow: hidden">
    <p>Form Groups:</p>
    <p>Total of 6 groups  approx.  4 people per group <a href="https://byu.az1.qualtrics.com/jfe/form/SV_2fyiNA7uMMOC7g9">https://byu.az1.qualtrics.com/jfe/form/SV_2fyiNA7uMMOC7g9</a></p>
    <p>I'll assign each group a proposal to turn into an actual survey. The survey should be estimated to take less than 10 minutes and include all the sections we have talked about in class</p>
    <ul>
      <li>Screener Questions</li>
      <li>Warm-up Questions</li>
      <li>Core Questions</li>
      <li>Build nuance and comparison</li>
      <li>Basic Demographics</li>
    </ul>
    <p>The proposal you are assigned will define the audience and the primary survey question.</p>
  </div>
  <h2 class="section-header" style="">Today's Lecture</h2>
  <div class="section-body" style="padding: 0 10px 10px 10px;border: solid #ccc 1px;overflow: hidden">
    <p>We are trying something new today as an experiment.  This is not for this class moving forward necessarily, but I am considering using a similar system for next semesters Core analytics class.</p>
    <p>We are using a platform called "NearPods" that can be accessed at: <a href="https://share.nearpod.com/qiZ9HRsghbb">https://share.nearpod.com/qiZ9HRsghbb</a></p>
    <p>You will need to visit the website using the link to launch the interactive lecture.  I'll want to hear your feedback after we have tried the experiment.</p>
  </div>
  <h2 class="section-header" style="">Notes from today's lecture</h2>
  <div class="section-body" style="padding: 0 10px 10px 10px;border: solid #ccc 1px;overflow: hidden">
    <h3>Main principle</h3>
    <p>Make it easy for respondents to provide you with information in a format that can be readily used</p>
    <h4>Example 1:</h4>
    <p>If you wanted to group respondents in to cohorts by age, how would you ask that question?</p>
    <p>What are the different options?</p>
    <ol>
      <li>What year were you born?
        <ul>
          <li>Drop down with years</li>
          <li>Direct entry in a text box</li>
          <li>Select question with categories</li>
        </ul>
      </li>
      <li>How old are you? - Use a grouped select question</li>
    </ol>
    <p>What are the pro's and con's from a respondents perspective?</p>
    <p>How will this question be used in analysis? - Most likely the response will be grouped together so we can use it to compare different age groups.</p>
    <p>Does this information change the way you think about asking this question?  (It should!)</p>
    <h4>Example 2</h4>
    <p>Where do you live?</p>
    <ul>
      <li>Enter Zip Code</li>
      <li>Enter state?</li>
      <li>Enter Region of the country?</li>
    </ul>
    <p>What are the trade-offs for each way of framing the question?  How do you decide?</p>
    <p>The important question again is how is this data going to be used?</p>
    <h3>It is very important that the analyst be involved in the creation of the survey!</h3>
    <code>Pro-tip: We usually provide too many options in surveys.  The more options, the harder it is to answer a question correctly. <br>
    This is not a question of honesty, but rather a problem with capability. </code>
    <h3>Main question types</h3>
    <ul>
      <li>Text Question</li>
      <li>Select Question
        <ul>
          <li>Single Select</li>
          <li>Multi select</li>
          <li>Drop down/Combo box</li>
          <li>Likert Scale</li>
          <li>Semantic Differential</li>
        </ul>
      </li>
      <li>Open-end (with or without validation</li>
      <li>Matrix or Grid Question</li>
      <li>Other Advanced Types
        <ul>
          <li>Ranking</li>
          <li>Constant Sum</li>
          <li>Heat-map/Image Select</li>
          <li>Slider</li>
        </ul>
      </li>
    </ul>
	<h3>Text Questions</h3>
	  <p>used to show test or images without expecting a response.</p>
	  <p>This is not really a question!</p>
	  <p>These questions have many uses.  Don't be shy about using them.  Some possibilities:
	  </p>
<ul>
<li>Introduction - build rapport</li>
	  <li>Provide instructions</li>
		  <li>Make transitions smoother</li>
		  <li>Present stimuli such as an ad or a policy</li>
		  <li>Provide context for a question such as providing a list of definitions or explanations</li>
	  </ul>
		<h5>Demo in Qualtrics</h5>
	<h3>Select Questions</h3>
	<p>There are three types of select questions:
	</p>
<ul>
		<li>
			Single Select <br>
			Also called:
			<ul>
				<li>Multiple Choice</li>
				<li>Single Punch</li>
				<li>Radio Field</li>
			</ul>
		</li>
	</ul>
	
	<p>This is the work horse of survey questions and accounts for the majority of questions.</p>
	<p>Most of the time researchers specify each of the available options as custom for a survey.  Qualtrics has a list of defaults
		response options for certain question types. This is convenient for programming a survey quickly, but they are of limited
		use for careful survey design. The problem is that even for basic question s like "Age" or "Gender" the target population 
		and the type of options that are appropriate will vary greatly.</p>
	<p>Select questions are used for two main purposes:
	</p>
<ul>
		<li>Collect "factual" information. (What questions?)</li>
		<li>Rate something on a scale that is meant to capture and attitude or feeling. (How questions?)</li>
	</ul>
	
	<h4>What questions</h4>
	<p>Factual information is relatively easy to see presented in a select question format. They are generally used for answer "What?" style questions (What, Where, When, Who)?</p>
	<p>There are a couple of hard things to keep in mind about what style select questions. To ask them effectively you need to
	</p>
<ol>
		<li>Ensure coverage for all <span class="underline" style="text-decoration: underline">plausible</span> options</li>
		<li>Ensure proper grouping of options for analysis.  (Remember that this will depend on the target respondent as well as anticipated analysis)</li>
	</ol>
	
	<p>A good Bad Example of radio button is the classic phone tree.  How often have you called, chatted, or contacted support in some other way, but 
		found that none of the paths were a good description of what the problem was? How did that feel?  What did you do to solve that problem?  
		This is exactly the issue that we have to solve with select questions.</p>
	<h5>A couple of solutions to be aware of:</h5>
	<ul>
		<li>Use Other (please specify) questions to allow respondents to supply answers you expect to be relatively rare. (Press 0 to speak with an operator)</li>
		<li>Pre-test/Pilot Test to ensure that you have proper coverage in your questions</li>
		<li>Utilize your business expertise or preliminary analysis of secondary data to understand expected responses</li>
	</ul>
	<h4>How questions</h4>
	<p>Questions that are collect thoughts and feelings are generally referred to as scale questions.  This is because respondents are expected to respond based on an 
	arbitrary if somewhat standardized scale.  I like to think of these questions as "How questions".</p>
	<p><span class="underline" style="text-decoration: underline">Example 2:</span> How do you feel about Apple's newly released iPhone?
		</p>
<ul>
			<li>I'm very excited</li>
			<li>I'm somewhat excited</li>
			<li>I'm neutral</li>
			<li>I'm somewhat disappointed</li>
			<li>I'm very disappointed</li>
		</ul>
	Note: This probably is not a survey question that you should actually be using.  There are a number of ways the wording could be improved
	<p><span class="underline" style="text-decoration: underline">Example 2:</span>On a scale of 1 to 10, How likely are you to recommend the movie you just saw to your friends and colleagues?
		</p>
<ul>
			<li>Very Likely - 10</li>
			<li>9</li>
			<li>8</li>
			<li>7</li>
			<li>6</li>
			<li>5</li>
			<li>4</li>
			<li>3</li>
			<li>2</li>
			<li>Very unlikely - 1</li>
		</ul>
	
	<p>There are a couple of reasons that questions like this are hard to write and hard to answer.  	The first is that many things are multi-dimensional, but the scale only reflects a single 
		dimension.  Take the movie example - I am fairly selective about the type of movie I recommend 
		to certain individuals.  There are many movies that I enjoy that I wouldn't recommend to my 
		parents.  These could be because of different standards around content, or simply because I 
		know their interests are different from mine when it comes to movies.  For example I don't 
		recommend that my parents watch the latest Marvel movie even if it did happen to be really 
		good. (It probably wasn't! F61C) They just don't care about marvel movies, but if I come 
		across a good movie based on a true story or a documentary you can bet they will hear about it.
	</p>
	<p>The most common type of scale is called a <span class="underline" style="text-decoration: underline">Likert Scale</span>.  This is a scale question that generally has 5 or seven points (Nearly always an odd number) that allows somebody to express that degree to which the agree or disagree with a statement.  The wording of the response options is generally not important for it to be a likert scale, but it most cover the complete range of options from 100% positive to 100% negative and it almost always includes a neutral point.</p>
	<p>We see Likert scale questions so often that most people don't think twice about them.  They do have some major drawbacks however.  The first is that they have been shown to be extremely susceptible to cues, social norms and desirability, context, culture, and cognitive biases.  This makes them particularly unreliable when used to measure cross culture attitudes and options.  The second problem is that they are fairly difficult to answer.  They often require a simplification of feelings on the part of the respondent and people don't hold options in their mind on a Likert scale.  It requires an individual to translate a feeling into a number on the fly.  This is uncomfortable for most people.</p>
	<p>Common Example: Online Review star ratings - people don't actually carry around a star rating for every product experience.  This star rating is only created when somebody gives a review.  On top of that we have collectively decided that only a 5-star review is a good review; anything less than that indicates a major flaw.</p>
	<p>Like star ratings 5-point scales have become the most common.  With 5 point scales, market researchers have developed some slang to refer to these ratings.  <span class="underline" style="text-decoration: underline">Top two box</span> refers to the highest two points on a scale.  This is used as short-hand for a positive response.  Anything less than top-two box is considered a negative response.  This only really works well for five point scales.  As you increase the number of scale points respondents become less likely to pick the extremes of the scale.</p>
	<h4>Weighting Scale Responses</h4>
	<p>In addition to converting 5 point scores into a binary scale using top-two box method, researchers often want to weight scale responses.  Consider the following question:</p>
	<p>Assuming that your local theater prices a movie ticket at $11.  How likely are you to purchase a ticket?
	</p>
<ul>
		<li>Definitely will</li>
		<li>Probably will</li>
		<li>Might or might not</li>
		<li>Probably will not</li>
		<li>Definitely will not</li>
	</ul>
	<p>If we are trying to predict the percentage of people purchasing a ticket we will probably want to weight the results to account for the people that said maybe/maybe not.</p>
	<p>The weights are completely arbitrary and usually decided by the researcher.  If they are conscientious they will attempt to adjust the weights based on similar questions about the subject in past studies that have been matched to actual purchase data.  This is actually a difficult problem however since we usually don't have purchase data and survey responses that match up.</p>
	<h5>One thing to try</h5>
	<p>Two point scales work really well in many situations.  Researchers often avoid them because they don't measure the strength of opinion directly, but in many cases that is a feature.  In many cases it appears to reduce bias and solve many of the problems present in traditional scales.  It avoids cultural effects, social desirability, and other forms of context specific answering.  It also may make the resulting analysis more accurate.  It is not necessarily appropriate for all situations, but I have successfully used it in many.</p>
	<h5>Multi select questions</h5>
	<p>Multi select questions are also commonly called check box questions, multi punch questions, or select all that apply.  That are used exclusively to answer "What" type questions similar to the way that factual select questions are.  Even though they are commonly grouped with select questions in the interface, it is best to think of them as a completely different question type.</p>
	<p>Technically multiple select questions are equivalent to a series of yes/no select questions.  They are treated exactly the same in the analysis.  The checkbox format is considered easier to answer however and the question can be presented more concisely.</p>
	<p>The same rules apply for the response option for multiple select questions as apply to select questions: Ensure coverage, group appropriately, and use an other (please specify) as needed.  There is one additional option for multiple select questions that doesn't apply to single selection questions.  A option can be marked as <span class="underline" style="text-decoration: underline">exclusive</span>, meaning that if that box is ticked all the other boxes are no longer valid and should be unchecked.  This can allow you to add an "Other" or "I don't know" option and still maintain data integrity.</p>
	<p>One issue to be aware of with multi-select questions is that the questions have a default answer.  If a respondent does not select an answer for a question, there is still "valid" data, all responses are not checked.  Defaults matter a lot so be careful if it is important for respondents to evaluate each option.  To combat this to some extent, software allows you to enforce a minimum and maximum number of items that need to be checked for a valid response.</p>
	<h4>Drop down</h4>
	<p>Just don't use it unless absolutely necessary.  It is designed to be able to fit more information in a small space, but it is not a great solution to most of the problems it tries to solve. It is even worse on mobile than on a desktop because you can't type a letter and scroll the list to a specific position.</p>
	<h4>Other select type questions</h4>
	There are other controls available on websites that you can use.  They are often called d combo boxes or multi-select boxes.  These are generally really bad ideas because most people don't know how to use them.  They have fallen out of favor even on the general web and not just in surveys.  Some software products include them just for completeness, but they are never recommended.
	<h3>Open End Questions</h3>
	<p>Open end questions are also called free entry or text box questions.  There are generally two types: short answer and multiple line.  The size of the text box provides a signal to respondents about how much they are expected to write.  In general a single line question will get a one word answer and a multi-line question will get a sentence answer.</p>
	<p>Open end questions also allow for validation to enforce a certain type of response.  For example you can force an open end to be an integer or an email address.  Commercial software has many of these validations built in and most will allow you to add your own although the way you do that will vary from platform to platform.  Validation is important because it solves one of the main problems with open end questions which is the terrible data quality.  Respondents favorite things to write in a text box are: None, N/A, and asdf.  This poor data quality makes them significantly less useful.</p>
	<h4>Require Response</h4>
	<p>One of the validation options available for open-end text boxes it to <span class="underline" style="text-decoration: underline">Require Response</span>.  This ensure that the text box is not empty when the respondent submits the question.</p>
	<p>Academic researchers actively discourage requiring a response, but it is widely used in business studies.  There are a couple of concerns that academic researchers have with requiring a response.  The first is that it is seen to encourage false answers.  If somebody doesn't want to or can't answer a question when you require a response they are more likely to make something up or answer untruthfully.  The second concern is related to the ethics of forcing respondents to provide an answer.  Generally forcing a response is considered bad practice for research studies where participation should be voluntary.</p>
	<p>I usually mark questions as requiring a response.  It is very helpful in reducing missing data which would necessitate removing the respondent from the study and does not appear to have major negative effects.  I don't necessarily agree with the ethical concerns either.  If studies are fielded anonymously over the internet a respondent can withdraw at any time by simply closing their browser window and walking away.  There is not any pressure to complete a survey so force does not seem to be a valid concern.</p>
	<p>When you use validation, you have to walk a fine line between being too specific and frustrating respondents and being too flexible and getting poor response quality.  The stricter the validation the more specific you need to make the instructions and the more mistakes respondents will make.  This can lead to respondents getting frustrated and giving up.</p>
	<h4>Short Answer</h4>
	<p>Short answer questions are generally used when there is a specific piece of information that is wanted, but that information needs to be collected at a highly granular level.  Common examples include product usage, years, or unaided recall.  It is possible to use validation to force responses into a narrow range of options.  For example you can make sure that year born is between 1920 and 2020.</p>
	<p>In most situation it is better to use a select question instead of a short answer question.  They serve the same purpose, but are generally easier to answer and enforce data quality.</p>
	<h4>Multi-line response</h4>
	<p>These are almost always used to ask "Why" questions.  It is common to elicit a response and then ask a "Why do you feel that way" as a follow-up.  It is common to dynamically ask a different question for positive and negative responses.</p>
	<p>These are the hardest question types to analyze and get good responses out of.  Most respondents do not type very much into these questions, but occasionally you get a really good quote that can be used to tell a compelling story.</p>
	<p>I wouldn't put too much stock into analyzing the answers however as the set of people that provide real responses to these questions is usually not representative or random.  This means that the insights you gain are really hard to generalize to the wider target audience.</p>
	<h3>Matrix/Grid questions</h3>
	<p>Matrix or grid questions are a hybrid of other question types that are simply used to make the survey more convenient to answer.  Most grid questions consist of a series of rows of select questions where the response options are the same for all the questions and the rows prompt a different response.</p>
	<p>They can reduce the perceived number of questions that the respondent needs to answer, but they take up quite a bit of screen real estate.  This causes problems on mobile devices where the entire question cannot fit on the screen. Requiring the respondent to scrolling is considered an large negative in surveys so a lot of attention is spent on making sure each question fits on a single screen. After open-end questions these are the most likely to cause a respondent to abandon the survey.</p>
	<p>A survey with a lot of grid questions can be annoying to respondents.  They are difficult to answer, but really easy to write so they have a tendency to make surveys take a long time. This along with mobile surveys is one of the reasons they seem to be falling out of favor with survey authors.</p>
	<h3>Semantic Differential</h3>
	<p>This is a a type of scale question that has opposite statements on each side.  Respondents are asked to pick a point on the scale that corresponds with the strength of their opinion regarding each statement.</p>
	<p>With a semantic differential question, the anchor statements should be the opposites of each other in order to make the comparison coherent.  They are used so that you can use balanced wording and avoid bias in the question phrasing.</p>
	<p>The reality is that that they are used only rarely in most surveys.  The difficult of coming up with parallel wording for the anchor points that are equally balanced is difficult and it is not clear that single anchor questions lead to significant bias.</p>
	<p>One other difficulty is that there is not a good way to indicate an neutral point making the question difficult to ensure a consistent response.</p>
	<h3>Ranking Questions</h3>
	<p>With ranking questions, respondents are asked to sort a set of statements from best to worst.  They are commonly used for things such as marketing messages where researchers are interested in finding options that are widely acceptable rather than simply a single best choice.</p>
	<p>Ranking questions have fallen out of favor as better methods have become available.  It is fairly difficult to rank most items as much of the time there are at least a few items that are seen as very similar.</p>
	<h3>Survey Flow</h3>
	<p>Demo of piping, branching, and skip logic.</p>
	<h3>MaxDiff Questions</h3>
	<p>MaxDiff questions are an alternative to ranking questions.  The output is very similar, but the questions are much easier for respondents to answer.  MaxDiff questions are not generally included in basic survey packages because they require additional analysis.  (There is an add on for Qualtrics that makes them available.)</p>
	<p>A MaxDiff question is actually a series of questions, usually 8-15, that ask respondents to evaluate a list of items and select the one that is seen as best and the one that is seen as worst.  Each screen of items usually includes only 3-5 items so the choices are usually much easier than a ranking question.  The researcher can then analyze the data after the fact to come up with score for the full list of items.</p>
	<p>The results of a MaxDiff are more informative than a simple rank ordering.  Each item has a continuous score that can be compared to all the other items and pairs of items.</p>
	<p>INCLUDE AN EXAMPLE OF A MAXDIF QUESTION AND THE RESULTING ANALYSIS</p>
	<p>Conjoint Analysis</p>
	<p>This question type can be seen as an more complicated version of MaxDiff.  We won't have time to talk about it in detail, but I wanted to give you a brief overview.  Conjoint analysis is primarily used in product design and pricing research and is very good and determining things like willingness to pay, purchase likelihood, suggesting pricing, and forecasting sales.</p>
	<p>Time permitting we will switch over to a presentation that goes into more detail.</p>
	</div>
  <!-- InstanceEndEditable --> 
  <!-- End custom HTML for Canvas Page --> 
</div>
</body>
<!-- InstanceEnd -->
</html>
